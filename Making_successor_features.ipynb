{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ratinabox\n",
    "from ratinabox.Environment import Environment\n",
    "from ratinabox.Agent import Agent\n",
    "from ratinabox.Neurons import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sr_update(firing_rates, next_firing_rates, M, alpha=0.002, gamma=0.995):  \n",
    "    \"\"\"The sr learning rule                                                    \n",
    "    Args:\n",
    "        firing_rates (vector): current firing rate of basis features \n",
    "        next_firing_rates (vector): firing rate of basis features at the next time step]\n",
    "        M (matrix): the SR matrix\n",
    "        alpha (float): the learning rate takes values in (0,1)\n",
    "        gamma (float): the discount factor takes values in (0,1)\n",
    "    Returns:\n",
    "        updated_M: the updated successor matrix\n",
    "    \"\"\"    \n",
    "    delta = np.outer(firing_rates.T + gamma * (M @ next_firing_rates.T) - (M @ firing_rates.T), firing_rates)\n",
    "    M += alpha * delta \n",
    "    return M, delta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sander_field_widths(Env,place_field_centres):\n",
    "    \"\"\"Get the place field widths for the Sander et al. (2019) experiment\n",
    "    Args:\n",
    "        Env (object): the environment object\n",
    "        place_field_centres (vector): the place field centres\n",
    "    Returns:\n",
    "        place_field_widths: the place field widths\n",
    "    \"\"\"\n",
    "    G = 0.74        #we use 0.74 for biologically plausible basis features, 0 for uniform gaussian basis features (gain in basis feature width moving away from wall)\n",
    "    H = 1 \n",
    "    W = 0.053       #we use 0.053 for biologically plausible basis features, 0.06 for uniform gaussian basis features\n",
    "    \n",
    "    wall_diffs = np.squeeze(np.diff(Env.walls,axis=1))\n",
    "    NS_WALLS = wall_diffs[:,0] == 0\n",
    "    EW_WALLS = wall_diffs[:,1] == 0\n",
    "    place_field_widths = np.zeros((len(place_field_centres),2))\n",
    "    for i in range(len(place_field_centres)):\n",
    "        dist_from_centre_to_walls = np.squeeze(np.linalg.norm(shortest_vectors_from_points_to_lines(place_field_centres[i], Env.walls),axis=-1))\n",
    "        ns_wall_dist = np.min(dist_from_centre_to_walls[NS_WALLS])\n",
    "        ew_wall_dist = np.min(dist_from_centre_to_walls[EW_WALLS])\n",
    "        place_field_widths[i,0] = G*(1/H - H/(H**2 + ns_wall_dist**2)) + W\n",
    "        place_field_widths[i,1] = G*(1/H - H/(H**2 + ew_wall_dist**2)) + W\n",
    "    return place_field_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import longest rodent trajectory or random walk path\n",
    "train_traj=pd.read_csv('Muessig_rat_trajectory.csv') \n",
    "train_traj=train_traj.to_numpy()\n",
    "\n",
    "xs = [item[0] for item in train_traj]\n",
    "ys = [item[1] for item in train_traj]\n",
    "\n",
    "coords_rescaled=[]\n",
    "for m in tqdm(range(0,len(xs))):\n",
    "  if math.isnan(xs[m])==False:\n",
    "    if math.isnan(xs[m])==False:\n",
    "      coords_rescaled.append([(xs[m])/1040,(ys[m])/1040])       #reshape trajectory to a box the same size and what is reported in that study's paper\n",
    "                                                          \n",
    "xs = [item[0] for item in coords_rescaled]\n",
    "ys = [item[1] for item in coords_rescaled]\n",
    "\n",
    "coords_rescaled = coords_rescaled[::2]                          #downsample trajectory to be 10-12 Hz (::2 for Sun and Muessig data, ::5 for Lever)\n",
    "\n",
    "xs = [item[0] for item in coords_rescaled]\n",
    "ys = [item[1] for item in coords_rescaled]\n",
    "\n",
    "times_=np.arange(0,len(coords_rescaled),1).tolist()\n",
    "\n",
    "len(coords_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View trajectory\n",
    "plt.scatter([item[0] for item in coords_rescaled],[item[1] for item in coords_rescaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RatInABox environment of the same size as that reported for the chosen study\n",
    "height = 25                                     \n",
    "length = 25\n",
    "dt = 1 \n",
    "\n",
    "Env = Environment( params = {'aspect':(length/105)/(height/105), \n",
    "               'scale':(height/100), \n",
    "              'dimensionality':'2D'});\n",
    "Ag = Agent(Env,\n",
    "            params = {\n",
    "                \"speed_mean\": 0.9,    \n",
    "                \"thigmotaxis\": 0.9})\n",
    "\n",
    "N_CELLS = 400\n",
    "TOTAL_TIME = len(coords_rescaled)\n",
    "\n",
    "x_centres = np.random.uniform(low=0.01, high=(length/100)-0.01 , size=(N_CELLS,))\n",
    "y_centres = np.random.uniform(low=0.01, high=(height/100)-0.1, size=(N_CELLS,))\n",
    "\n",
    "place_field_centres = np.vstack((x_centres,y_centres)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a population of place cell basis features\n",
    "place_field_widths = get_sander_field_widths(Env,place_field_centres)\n",
    "\n",
    "PCs = PlaceCells(Ag,\n",
    "                 params={'n': N_CELLS,\n",
    "                         'description':'product_of_gaussians_threshold', #if creating basis features to be downloaded, use 'product_of_gaussians' without threshold\n",
    "                         'widths':place_field_widths, \n",
    "                         'wall_geometry':'geodesic',\n",
    "                         'place_cell_centres': place_field_centres, \n",
    "                         'max_fr':10,\n",
    "                         'min_fr':0,\n",
    "                         'color':'C1'})\n",
    "\n",
    "fig, ax = plt.subplots(10, 10)\n",
    "fig, ax = PCs.plot_rate_map(fig=fig, ax=ax, method='groundtruth',colorbar=False, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot those basis features \n",
    "pc_rm = []\n",
    "for i in range(0,len(rate_maps)):\n",
    "  rm = rate_maps[i].reshape(length, height) \n",
    "  rm1 = rm/np.nansum(rm)\n",
    "  rm1 = rm1 - np.percentile(rm1,40)\n",
    "  rm1[rm1 < 0] = 0\n",
    "  pc_rm.append(rm1)\n",
    "\n",
    "def plot_cells(cells, n, m, rm, cell_type = ''):        \n",
    "    fig = plt.figure()\n",
    "    fig.set_figheight(20)\n",
    "    fig.set_figwidth(15)\n",
    "    for i in np.arange(n*m):\n",
    "        ax = plt.subplot(n, m, i+1)\n",
    "        ax.imshow(cells[i], cmap='jet')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_title(cell_type+str(i+1))\n",
    "    plt.subplots_adjust(hspace=0.5,wspace=0.3)\n",
    "\n",
    "plot_cells(cells=pc_rm, n=10 , m=10, rm=ra_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save ratemaps of basis features (unthresholded)\n",
    "rate_maps = PCs.get_state(evaluate_at=\"all\")\n",
    "rate_maps.shape\n",
    "\n",
    "for i in range(0,len(rate_maps)):\n",
    "  rm = rate_maps[i].reshape(25,25) \n",
    "  rm1 = rm/np.nansum(rm)\n",
    "  rm1 = rm1 - np.percentile(rm1,40)\n",
    "  rm1[rm1 < 0] = 0\n",
    "  #np.save('{}.npy'.format(i), rm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn successor features from basis features\n",
    "dt = 1\n",
    "T = len(coords_rescaled)\n",
    "\n",
    "Ag.import_trajectory(times=times_, positions=coords_rescaled)\n",
    "for i in tqdm(range(0,len(times_))):\n",
    "\n",
    "    Ag.update(dt=dt)\n",
    "    PCs.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trajectory to ensure fits inside RatInABox environment\n",
    "fig, ax = PCs.plot_place_cell_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, plot agent heatmap and basis feature centres\n",
    "fig, ax = Ag.plot_position_heatmap()\n",
    "fig, ax = Ag.plot_trajectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise SR matrix and update along each point of downsampled trajectory\n",
    "M = np.eye(N_CELLS) \n",
    "deltas = []\n",
    "for i in range(len(PCs.history['firingrate'])-3):    \n",
    "    firing_rate = np.array(PCs.history['firingrate'][i])\n",
    "    next_firing_rate = np.array(PCs.history['firingrate'][i+1])\n",
    "    if np.linalg.norm(Ag.history['vel'][i]) > 0.0001:                           #speed filter on SR update\n",
    "        M, delta = sr_update(firing_rate, next_firing_rate, M)\n",
    "        deltas.append(np.mean(delta))\n",
    "\n",
    "len(deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sPlot resulting SR matrix, M:\n",
    "plt.imshow(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the trend of deltas to ensure training has stabilised:\n",
    "plt.plot(np.convolve(deltas, np.ones(6000)/6000, mode='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate successor features:\n",
    "ss = 1.8        #smoothing sigma \n",
    "def bin_data_for_histogramming(data, extent, dx, weights=None):\n",
    "    if len(extent) == 2:  \n",
    "        bins = np.arange(extent[0], extent[1] + dx, dx)\n",
    "        heatmap, xedges = np.histogram(data, bins=bins, weights=weights)\n",
    "        centres = (xedges[1:] + xedges[:-1]) / 2\n",
    "        return (heatmap, centres)\n",
    "\n",
    "    elif len(extent) == 4:  \n",
    "        bins_x = np.arange(extent[0], extent[1] + dx, dx) \n",
    "        bins_y = np.arange(extent[2], extent[3] + dx, dx)\n",
    "        heatmap, xedges, yedges = np.histogram2d(\n",
    "            data[:, 0], data[:, 1], bins=[bins_x, bins_y], weights=weights\n",
    "        )\n",
    "        heatmap = heatmap.T[::-1, :]\n",
    "        return heatmap\n",
    "\n",
    "ra_maps=[]\n",
    "for i in tqdm(range(PCs.n)):\n",
    "  startid=0\n",
    "  endid=len(Ag.history['t'])\n",
    "  chosen_neuron=i\n",
    "  ex = Ag.Environment.extent\n",
    "  pos = np.array(Ag.history[\"pos\"])[startid:endid] \n",
    "\n",
    "  rate_timeseries = np.array(PCs.history[\"firingrate\"])[startid:endid].T\n",
    "  rate_timeseries_ = rate_timeseries[chosen_neuron, :]\n",
    "  rate_map = bin_data_for_histogramming(data=pos, extent=ex, dx=0.01, weights=rate_timeseries_) \n",
    "  ra_maps.append(rate_map)\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "class SuccessorFeature:\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "        self.rate_map = None\n",
    "\n",
    "def calculate_successor_features(basis_cells, M, rm, threshold=True):\n",
    "    print('')\n",
    "    print('Calculating successor features')\n",
    "    smoothing_sigma = ss\n",
    "    successor_features = []\n",
    "    for i in tqdm(np.arange(basis_cells.n)):\n",
    "        # initialise successor feature\n",
    "        c = SuccessorFeature() \n",
    "        c.rate_map = np.zeros(np.shape(rm[i]))\n",
    "        # get successor feature weights\n",
    "        c.weights = M[i, :]\n",
    "        # sum inputs\n",
    "        for j in np.arange(basis_cells.n):\n",
    "            c.rate_map += rm[j] * c.weights[j]\n",
    "        # normalize and threshold maps\n",
    "        c.rate_map = c.rate_map / np.amax(c.rate_map)\n",
    "        c.rate_map = gaussian_filter(c.rate_map, smoothing_sigma)\n",
    "        #if threshold == True:\n",
    "            #c.rate_map = np.maximum(c.rate_map - 0.8, 0) #removed thresholding for successor_features\n",
    "        successor_features.append(c)\n",
    "    return successor_features\n",
    "\n",
    "successor_features = calculate_successor_features(basis_cells=PCs,M=M,rm=ra_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot resulting successor features\n",
    "def plot_cells(cells, n, m, rm, cell_type = ''):         \n",
    "    fig = plt.figure()\n",
    "    fig.set_figheight(20)\n",
    "    fig.set_figwidth(15)\n",
    "    for i in np.arange(n*m):\n",
    "        ax = plt.subplot(n, m, i+1)\n",
    "        ax.imshow(cells[i].rate_map, cmap='jet')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_title(cell_type+str(i+1))\n",
    "    plt.subplots_adjust(hspace=0.5,wspace=0.3)\n",
    "\n",
    "plot_cells(cells=successor_features, n=10 , m=10, rm=ra_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ratemaps from resulting successor features\n",
    "for m in range(len(successor_features)):\n",
    "    sf = successor_features[m].rate_map\n",
    "    sf1 = sf/np.nansum(sf)\n",
    "    sf1 = sf1 - np.percentile(sf1,40)\n",
    "    sf1[sf1 < 0] = 0\n",
    "    #np.save('SF_{}.npy'.format(m), sf1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating shuffled successor features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "from numpy.random import shuffle\n",
    "\n",
    "def shuffle_along_axis(a, axis):\n",
    "    idx = np.random.rand(*a.shape).argsort(axis=axis)\n",
    "    return np.take_along_axis(a,idx,axis=axis)\n",
    "\n",
    "for i in tqdm(range(0,20)):\n",
    "    M1 = shuffle_along_axis(M, axis=1)\n",
    "    successor_features1 = calculate_successor_features(basis_cells=PCs,M=M1,rm=ra_maps)\n",
    "\n",
    "    for m in range(len(successor_features1)):\n",
    "        sf = successor_features1[m].rate_map\n",
    "        sf1 = sf/np.nansum(sf)\n",
    "        sf1 = sf1 - np.percentile(sf1,5)\n",
    "        sf1[sf1 < 0] = 0\n",
    "        #np.save('shuffle_{}_{}.npy'.format(i,m), sf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
